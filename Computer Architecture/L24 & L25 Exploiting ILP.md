#ILP
- If only 1 instruction issued every clock cycle, CPI >= 1
	- Ideal CPI is 1

To achieve CPI <= 1, issue multiple instructions every clock cycle

**Multiple Issue processors can be classified into:**
- Compiler: statically scheduled super-scalar processors
	- In order execution if they are statically scheduled
- Runtime: Dynamically scheduled super-scalar processors
	- Out of order execution if they are dynamically scheduled
- Compiler: Very Long Instruction Word (VLIW) processors
	- Issues fixed number of instructions formatted either as one large instruction or a fixed instruction package (bundle) with parallelism among instructions explicitly indicated by instruction
	- Similar to VLIW --> EPIC

## Multiple Issue Processors

![[Pasted image 20251024074211.png]]

- Superscalar: Multiple instructions that can be issued at the same time
	- Static: By compiler --> HW to detect all dependences --> Execute in order
	- Dynamic: Tomasulo's is an example --> out-of-order --> none without speculation
	- Speculative: Out of order execution with speculation --> Latest intel/amd chips
- VLIW --> Anything larger than 2 instructions is very large, 2 is "large instruction word". Compiler is the one that looks at all dependences --> Hazards by compiler --> Used in signal processing
	- Ex: Loop unrolling is good example
- EPIC --> Similar to VLIW. Either are not super common

Why is static superscalar with dynamic issue structure?:
	Similar to VLIW, compiler determines sequence of instructions.
	--> Static issue: whatever order instruction comes in, issue
	--> Dynamic: HW defines when to issue instructions
	**Only issuing one instruction that comes out. If no hazards, it can start issuing new instructions**
		In VLIW, static issue because instructions issued are fixed

### VLIW Processors

- Compiler packages instructions, then they could be executed in parallel
	- If not independent, it can put a NO-OP in the instruction bundle

- Package multiple operations in one instruction
- Example:
	- One integer instruction (or branch)
	- Two independent FP operations
	- Two independent memory references
- Need enough parallelism in code to fill available slots

- Each instruction has explicit coding for multiple operations
	- "packet"
- Trade-off instruction space for simple decoding
- **All Operations in each instruction execute in parallel**
- Need compiling technique that schedules across several branches
- Assume compiler can figure out parallelism and assume correct

### Loop Unrolling in VLIW

- Recall fld to fadd needs 1 cycle in between, and add to store 2 cycles
- Ex: Unrolling 7 times:
- ![[Pasted image 20251024081738.png]]

### Problems with 1st gen VLIW

- Increase code size
	- Very long unroll to generate enough operations in straight line
	- Whenever VLIW instructions not full, unused functional units translate to wasted bits in instruction encoding
- Operated in lock-step. No hazard detection HW
	- No hardware checking
	- Stall in any functional unit pipeline caused entire processor and all operations of the instruction to stall, since all functional units need to be synchronized
	- Caches hard to predict
- Binary code compatibility
	- Need different binary to use architecture
	- Pure VLIW -> different numbers of functional units and unit latencies require different versions of code

## Dynamically-Scheduled Superscalar

- Issue multiple instructions per clock in dynamically scheduled processor is complex
	- Instructions may depend on one another
	- Tables (reg status, reorder buffer, etc) must be updated in parallel
		- If not, incorrect. You may even lose some dependences
- How to issue multiple instructions per cycle (let's assume 2-issue processor)
	- Run issue step in half a clock cycle so two can be processed
		- Cannot be extended
	- Build logic to handle 2 or more instructions at once
		- Must include handling dependences

### Issue Stage

- Bottleneck in dynamically scheduled superscalars
	- Number of combinations that must be checked for dependences grows as square of instructions issued in clock cycle
- Updated issue logic --> assign reservation station, ROB for every instruction that could be issued in next issue bundle --> must be done in single clock cycle
	- Can be done before instruction decoded by ensuring enough reservation stations available to issue bundle
		- Limit number of instructions in a bundle
	- Analyze all dependences that can exist in issue bundle
	- Assign appropriate ROB number on reservation table and update reservation table

### Ex: 2 Issue Processor (No Speculation)

![[Pasted image 20251024184955.png]]

- Branch instruction issued by itself in 3rd clock cycle because you don't know branch result. Until outcome known, next instruction is not issued
- When waiting, instruction sitting in store buffer

#### Same Ex (With Speculation)

![[Pasted image 20251024184559.png]]

Extra step: You need to commit

- Add doesn't need to wait until commit executes, as it receives from CDB

- Load issued in clock cycle 4 because the branch 
	- You need to predict. Branch instruction prediction tells you what instruction to issue next

### Branch Target Buffer

- Need high instruction bandwidth
	- Branch target buffer: Cache what next address is
		- Next PC prediction buffer, indexed by current PC

- ![[Pasted image 20251024190334.png]]
- Look at the branch target buffer for predicted PC on every instruction. 
- **Entries in this buffer are only the branch instructions** (or jumps)

Flowchart:

![[Pasted image 20251024201444.png]]

- If instruction not taken, continue instruction execution
- If mispredict, delete entry from target buffer
- It's the same logic as a TLB

### Branch Target Buffer Penalty

- Only penalty when instruction in buffer. Predict as taken but not taken
- Two clock cycle penalty when not taken --> 1 to update buffer with correct information
	- can't fetch another in this time
	- Restart instruction fetch is another clock cycle

### Branch Folding --> Optimization

- Larger branch-target buffer
- **Add target instruction into buffer to deal with longer decoding time required by large buffer**
	- Branch folding
- Instead of storing PC{I5}, store Instruction directly --> no need to go back to fetch --> can issue right away

### Return Address Prediction

- Must unconditional branches come from function returns
- Same procedure can be called from multiple sites
	- Causes buffer to forget about return address from previous calls
- Some have separate return address buffer organized as a stack

#### Benchmarks:

![[Pasted image 20251024202645.png]]

## Integrated Instruction Fetch Units

- Integrated branch prediction
	- Branch predictor part of IF unit and constantly predicting branches
- Instruction prefetch
	- IF units to deliver multiple instructions per clock, integrating with branch prediction
- Instruction memory access and buffering
	- Fetch multiple instructions per cycle
		- May require accessing multiple cache blocks (prefetch to hide cost of crossing cache blocks)
		- Provides buffering, acting as on-demand unit to provide instructions to issue stage as needed and in quantity needed

#### Speculation - Reg Renaming

- Instead of virtual registers from reservation stations and reorder buffer, create single register pool
- Instead of reorder buffer use physical registers. Do everything in physical regs, single source to get values from
	- No need to update ROB and registration stations
	- It replaces ROB from storage standpoint
- Simplifies commit
- De-allocation is more difficult

#### Integrated Issue and Renaming

- Combine instruction issue with reg renaming
	- Issue logic pre-reserves enough physical regs for the bundle
	- Issue logic finds dependences within bundle, maps regs as necessary
	- Issue logic finds dependencies between current bundle and in-flight bundles, maps regs as necessary
- Pre-fixed with "p" and mapped to actual reg
![[Pasted image 20251027231342.png]]

#### How much to Speculate?

- Mis-speculation degrades performance
- Prevent speculative code from higher costing misses (like L2)
